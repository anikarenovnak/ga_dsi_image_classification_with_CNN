{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review of the Problem Statement and the Methods Used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I have built an image classification model which uses a convolutional neural network to classify images into their respective 5 categories. The purpose of this project is to use this model to demonstrate how some approaches can be applied to help us understand what goes on inside the black box of a neural network. Such understanding can provide valuable insights into\n",
    "\n",
    "### 1. the limitations of the model in general \n",
    "### 2. where and why the model may fail to correctly predict classes of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The methods used where \n",
    "<br/>\n",
    "1. Grouping misclassified images using manual visual inspection of them to determine wheter there may be shared patterns of doodles that systematically confuse the neural network and cause it to misclassify\n",
    "2. Visualizing the output of hidden layers - a technique used to help understand what features the neural network is selecting to learn at each layer \n",
    "\n",
    "![all_doodles](../images/all_doodles.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why this problem is useful\n",
    "\n",
    "The prupose of this project was not to undersatnd the inner workings of the model, but to demonstrated approaches that can be used to help achieve this understanding. This project was more of a research problem rather than one that directly translates into business value. This is not to say that business value from this type of research cannot be acquired. Such research is crucial to gain undersatnding about how a deep learning model works - specifically, **where and why the model is expected to fail or underperform** as I've kept the focus so far. This understanding is in turn a critical part in developing a good quality, realiable AI product such as Amazon's Alexa or Apple's Siri. Therefore the problem statement I've explored in this project is aimed at data science teams and researchers at groups that are actively working on the development of AI products. \n",
    "\n",
    "It is an obvious truism that improving the quality of such an AI product thanks to research will translate into business value in the long term. But morover, the research used to develop better quality AI products is also very useful in advancing our understanding about deep learning in general. I see this problem as a sweet spot of the balance between research and industry and that's why it's been so exciting for me to explore. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps \n",
    "\n",
    "1. Continute with disecting the model with the methods used in this project which barely scratched the surface \n",
    "2. Understand the contribution of individual noads within hidden layers by tuning their acivation functions or the weights that go into it: exaggerrating or dimming the output of a single node\n",
    "3. Scaling the model to learn on a much larger dataset using cloud computing such as Amazon Web Services\n",
    "5. Establish a criteria for what type of misclassifications are acceptable and what aren't (if we train the model with a random image of a scribble that has no discernable pattern of a cat but whih has the label of a cat, is it reasonable for us to expect the model to learn to classify such an image as a cat?)\n",
    "4. Upon gaining more understanding about the model, tune it in an informed way to reduce the number of unacceptable misclassifications and therefore to improve its predictive power\n",
    "5. Tackle overfitting to ensure the model generalizes to unseen data when deployed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often times in data science we speak of prediction vs inference. Some models are built to predict really well which often comes at the cost of losing interpretation. Better prediction can usually be achieved with fancy ensembling or meta-ensembling techniques which inevitably lead to a loss of our understanding on what happens under the hood of the model. Preserving good interpretation of the model often means keeping it very simple - and that, conversly often times comes at the cost of not achieving desired prediction performance. \n",
    "\n",
    "Of course this is not to say that prediction models are better than inference focused models and vice versa. There is a tradeoff that must be considered and decided upon based on every problem at hand. The choice of model depends on the dataset but also on the data science problem itself. \n",
    "\n",
    "Ideally, we would build a model that is optimized for prediction AND interpretation at the same time. While this is generally a difficult goal to achieve, it's possible to move closer towards it: **my recommendation is that companies invest some of their funds into research - something that is time consuming and costly, but of very high reward in the long term.** \n",
    "\n",
    "Research into undersatnding how a model works under the hood can help drive and improve a model's predictive power by tuning the model or changing its architecture in the case of neural networks in an informed/educated way. This can also scale quickly because with such research more general discoveries about deep learning models can be achieved that will can be applied to new problems in the future. This is especially useful in the case of neural networks for which the complexity of a model can get so rich that running a grid search to tune the hypaerparamters can be painfully computationally expensive and may take a very long time. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
